{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All the search results were combined, and then the micropeptide repeats were combined to integrate as many expressions as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/qz64tv_j35d5ts5ksf1t8r_40000gn/T/ipykernel_86112/700207066.py:5: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../02p_exp/combine_all.csv', sep=',', header=None)\n",
      "/var/folders/30/qz64tv_j35d5ts5ksf1t8r_40000gn/T/ipykernel_86112/700207066.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_duplicates = duplicates.groupby(0).apply(lambda x: x.fillna(method='ffill').fillna(method='bfill')).drop_duplicates()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('../02p_exp/combine_all.csv', sep=',', header=None)\n",
    "\n",
    "# search duplicates\n",
    "duplicates = df[df.duplicated(subset=0, keep=False)]\n",
    "\n",
    "# Merge duplicates\n",
    "merged_duplicates = duplicates.groupby(0).apply(lambda x: x.fillna(method='ffill').fillna(method='bfill')).drop_duplicates()\n",
    "\n",
    "# update df\n",
    "df = pd.concat([df[~df[0].isin(duplicates[0])], merged_duplicates])\n",
    "\n",
    "# check duplicates\n",
    "duplicates_after_merge = df[df.duplicated(subset=0, keep=False)]\n",
    "\n",
    "# if there are still duplicates, keep the first one\n",
    "df = df.drop_duplicates(subset=0, keep='first')\n",
    "\n",
    "df.to_csv('../02p_exp/sample_raw_uni.csv', sep=',', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Assign the sample name to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sample_names = []\n",
    "with open('../../source/PDC_study_experimental.csv', 'r') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        values = row[3:13]\n",
    "        for value in values:\n",
    "            split_values = value.split('\\n')\n",
    "            first_split = split_values[0]\n",
    "            last_split = split_values[-1].split(' ')[-1]\n",
    "            extracted_value = first_split + '_' + last_split\n",
    "            sample_names.append(extracted_value)\n",
    "\n",
    "# Replace column names\n",
    "with open('../02p_exp/sample_raw_uni.csv', 'r') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    rows = list(reader)\n",
    "rows[0][1:] = sample_names\n",
    "\n",
    "with open('../02p_exp/sample_raw_case.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tumor Normal was grouped and sorted and orderedd, and mat missing values were filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('~/test.txt',sep=\"\\t\")\n",
    "\n",
    "tumor_columns = [col for col in df.columns if 'Tumor' in col]\n",
    "normal_columns = [col for col in df.columns if 'Normal' in col]\n",
    "\n",
    "# order： normal_columns + tumor_columns\n",
    "new_columns =  normal_columns + tumor_columns\n",
    "new_df = df[new_columns]\n",
    "\n",
    "new_df.to_csv('/Users/suxinwan/Desktop/test-0325.csv', index=False)\n",
    "\n",
    "# print the number of columns containing 'Tumor' and 'Normal'\n",
    "print(\"Tumor number：\", len(tumor_columns))\n",
    "print(\"Normal number：\", len(normal_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Differential expression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import multitest\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('~/test.csv',index_col=0)\n",
    "sample_columns = data.filter(regex='Tumor|Normal').columns\n",
    "\n",
    "result_data = pd.DataFrame(columns=['orf_id', 'T-Statistic', 'P-Value', 'Log2FC', 'FDR'])\n",
    "\n",
    "# store logFC\n",
    "logfc_values = pd.Series(index=data.index)\n",
    " \n",
    "# t.test \n",
    "for _, row in data.iterrows():\n",
    "\n",
    "    normal_data = row[sample_columns].values[:11]\n",
    "    tumor_data = row[sample_columns].values[12:]\n",
    "\n",
    "    t_statistic, p_value = stats.ttest_ind(tumor_data, normal_data)\n",
    "\n",
    "    # calculate logFC\n",
    "    tumor_mean = np.mean(tumor_data)\n",
    "    normal_mean = np.mean(normal_data)\n",
    "    fc = np.log2(tumor_mean / (normal_mean+0.0001))\n",
    "\n",
    "    logfc_values[row.name] = fc\n",
    "\n",
    "    # add result\n",
    "    result_data = pd.concat([result_data, pd.DataFrame({'orf_id': [row.name], 'T-Statistic': [t_statistic], 'P-Value': [p_value], 'Log2FC': [fc]})], ignore_index=True)\n",
    "\n",
    "# calculate FDR\n",
    "p_values = result_data['P-Value']\n",
    "fdr = multitest.multipletests(p_values, method='fdr_bh')[1]\n",
    "\n",
    "# add result to result_data\n",
    "result_data['FDR'] = fdr\n",
    "result_data.to_csv(\"~/de_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/qz64tv_j35d5ts5ksf1t8r_40000gn/T/ipykernel_94460/2991975778.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  significant_rows['ENSG_ID'] = ensg_ids\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyensembl import EnsemblRelease\n",
    "\n",
    "# load ensembl\n",
    "ensembl = EnsemblRelease(110)\n",
    "\n",
    "df = pd.read_csv('../02p_exp/de_sample.csv')\n",
    "\n",
    "# select p < 0.05\n",
    "significant_rows = df[df['P-Value'] < 0.05]\n",
    "\n",
    "first_column = significant_rows.iloc[:, 0]\n",
    "split_values = first_column.str.split('_')\n",
    "\n",
    "ensg_ids = []\n",
    "for split_value in split_values:\n",
    "    try:\n",
    "        enst_id = split_value[0]  \n",
    "        ensg_id = ensembl.transcript_by_id(enst_id).gene_id\n",
    "    except Exception as e:\n",
    "        ensg_id = 'NA'\n",
    "    ensg_ids.append(ensg_id)\n",
    "\n",
    "# add ENSG\n",
    "significant_rows['ENSG_ID'] = ensg_ids\n",
    "\n",
    "significant_rows.to_csv('../02p_exp/de_sample_with_ensg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The expression of differential RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../02p_exp/sample_de_order.csv\")\n",
    "\n",
    "orf_id_data = data[data[\"orf_id\"].notnull()]\n",
    "\n",
    "# select tumor\n",
    "selected_columns = [\"orf_id\"] + [col for col in data.columns if \"Tumor\" in col]\n",
    "orf_id_tumor_data = orf_id_data[selected_columns]\n",
    "\n",
    "subset_list = pd.read_csv(\"../04co_exp/ucec_de_list.txt\", sep=\"\\t\")\n",
    "\n",
    "# merge data\n",
    "result_data = pd.merge(orf_id_tumor_data, subset_list, on=\"orf_id\")\n",
    "result_data.to_csv(\"../04co_exp/de_case_exp.csv\", index=False)\n",
    "\n",
    "# read count matrix\n",
    "count_matrix = pd.read_csv(\"../03r_exp/case_COUNT_matrix.csv\")\n",
    "count_matrix['ENSG_ID'] = count_matrix['ENSG_ID'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "intersect_ensg = subset_list['ENSG_ID']\n",
    "\n",
    "# select matched rows\n",
    "matched_rows = count_matrix[count_matrix['ENSG_ID'].isin(intersect_ensg)]\n",
    "matched_rows.to_csv(\"../04co_exp/matched_count_matrix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# obtain ENSG ID values\n",
    "df1 = pd.read_csv('../02p_exp/de_sample_with_ensg.csv')\n",
    "ensg_ids = df1['ENSG_ID'].tolist()\n",
    "\n",
    "df2 = pd.read_csv('../04co_exp/matched_count_matrix.csv')\n",
    "\n",
    "new_rows = []\n",
    "for ensg_id in ensg_ids:\n",
    "    rows_to_copy = df2[df2['ENSG_ID'] == ensg_id]\n",
    "    for index, row in rows_to_copy.iterrows():\n",
    "        new_row = row.to_list()\n",
    "        new_row.insert(0, ensg_id)\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "new_df = pd.DataFrame(new_rows, columns=['ENSG_ID'] + df2.columns.tolist())\n",
    "new_df.to_csv('../04co_exp/matched_out_matrix_updated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "protein_file = \"../04co_exp/de_p_exp.csv\"\n",
    "protein_df = pd.read_csv(protein_file, sep=\",\")\n",
    "\n",
    "# read rna expression data\n",
    "rna_file = \"../04co_exp/de_r_exp.csv\"\n",
    "rna_df = pd.read_csv(rna_file, sep=\",\")\n",
    "\n",
    "# select value for calculation\n",
    "genes = protein_df.columns[2:]\n",
    "\n",
    "# store result\n",
    "result_df = pd.DataFrame(columns=[\"Gene\", \"R\",\"P\"])\n",
    "\n",
    "# caluclate correlation value\n",
    "for gene in genes:\n",
    "    protein_tumor = protein_df[gene]\n",
    "    rna_tumor = rna_df[gene]\n",
    "    rna_data = rna_df[gene]\n",
    "    \n",
    "    #protein_tumor_rna_tumor_correlation, tumor_pvalue = stats.spearmanr(protein_tumor, rna_tumor)\n",
    "    protein_tumor_rna_tumor_correlation, tumor_pvalue = stats.pearsonr(protein_tumor, rna_tumor)   \n",
    "    result_df.loc[len(result_df)] = [gene, protein_tumor_rna_tumor_correlation,tumor_pvalue]\n",
    "\n",
    "\n",
    "result_file = \"../04co_exp/correlation_results.csv\"\n",
    "result_df.to_csv(result_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilearnplus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
